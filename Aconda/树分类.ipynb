{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32952fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2f5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读文件\n",
    "data=pd.read_csv('again.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bdba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将dataframe格式转换成list\n",
    "data.iloc[0:2]\n",
    "index=data['CATE_NAME_LV1']=='手机数码'\n",
    "data=data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd48533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>ITEM_PRICE</th>\n",
       "      <th>ITEM_SALES_VOLUME</th>\n",
       "      <th>CATE_NAME_LV1</th>\n",
       "      <th>CATE_NAME_LV2</th>\n",
       "      <th>CATE_NAME_LV3</th>\n",
       "      <th>CATE_NAME_LV4</th>\n",
       "      <th>CATE_NAME_LV5</th>\n",
       "      <th>Label1</th>\n",
       "      <th>Label2</th>\n",
       "      <th>Label3</th>\n",
       "      <th>Label4</th>\n",
       "      <th>Label5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>634256348035</td>\n",
       "      <td>定诺三防热敏纸55-60宽*70 75 15 20 30 40 50 80 85 90 10...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1</td>\n",
       "      <td>手机数码</td>\n",
       "      <td>办公设备/耗材/相关服务</td>\n",
       "      <td>办公用纸</td>\n",
       "      <td>标签打印纸/条码纸</td>\n",
       "      <td>Nan</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>403</td>\n",
       "      <td>3963</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>634400640726</td>\n",
       "      <td>初中物理电学实验器材全套初三电学实验箱初二电磁铁实验器材电磁学实验箱简单电路焦耳定律电动机</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6</td>\n",
       "      <td>手机数码</td>\n",
       "      <td>电子词典/电纸书/文化用品</td>\n",
       "      <td>教学演示/展示告示用品</td>\n",
       "      <td>教学仪器/实验器材</td>\n",
       "      <td>Nan</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>978</td>\n",
       "      <td>3484</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       ITEM_ID  \\\n",
       "20          22  634256348035   \n",
       "22          24  634400640726   \n",
       "\n",
       "                                            ITEM_NAME  ITEM_PRICE  \\\n",
       "20  定诺三防热敏纸55-60宽*70 75 15 20 30 40 50 80 85 90 10...         6.6   \n",
       "22      初中物理电学实验器材全套初三电学实验箱初二电磁铁实验器材电磁学实验箱简单电路焦耳定律电动机        68.0   \n",
       "\n",
       "    ITEM_SALES_VOLUME CATE_NAME_LV1  CATE_NAME_LV2 CATE_NAME_LV3  \\\n",
       "20                  1          手机数码   办公设备/耗材/相关服务          办公用纸   \n",
       "22                  6          手机数码  电子词典/电纸书/文化用品   教学演示/展示告示用品   \n",
       "\n",
       "   CATE_NAME_LV4 CATE_NAME_LV5  Label1  Label2  Label3  Label4  Label5  \n",
       "20     标签打印纸/条码纸           Nan       5      34     403    3963      37  \n",
       "22     教学仪器/实验器材           Nan       5     134     978    3484      37  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a94abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#树类型的定义\n",
    "class TreeNode(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parent = None\n",
    "        self.child = []\n",
    "\n",
    "    def __repr__(self) :\n",
    "        return '%s' % self.name\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.name)\n",
    "\n",
    "    def add_child(self, name):\n",
    "        for n in range(len(self.child)):\n",
    "            if name == self.child[n].name:\n",
    "                return self.child[n]\n",
    "        obj = TreeNode(name)\n",
    "        obj.parent = self\n",
    "        self.child.append(obj)\n",
    "        return obj\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.child)\n",
    "\n",
    "    def dump(self, indent=0):\n",
    "        tab = '    '*(indent-1) + ' |- ' if indent > 0 else ''\n",
    "        print('%s%s' % (tab, self.name))\n",
    "        for i in range(len(self.child)):\n",
    "            self.child[i].dump(indent+1)\n",
    "\n",
    "    def func(self):\n",
    "        y=[]\n",
    "        for i in range(len(self.child)):\n",
    "            for j in range(len(self.child[i].child)):\n",
    "                for k in range(len(self.child[i].child[j].child)):\n",
    "                    for l in range(len(self.child[i].child[j].child[k].child)):\n",
    "                            x=[]\n",
    "                            for m in range(len(self.child[i].child[j].child[k].child[l])):\n",
    "                                x.append(self.child[i].child[j].child[k].child[l].child[m])\n",
    "                            y.append(x)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aafb0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "root = TreeNode('手机数码')\n",
    "for i in range(len(data)):\n",
    "    a1 = root.add_child(data.iloc[i,6])\n",
    "    b1 = a1.add_child(data.iloc[i,7])\n",
    "    c1 = b1.add_child(data.iloc[i,8])\n",
    "    d1 = c1.add_child(data.iloc[i,9])\n",
    "    d1.add_child(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2e30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#树根节点下第一层有多少分支\n",
    "\n",
    "z=root.func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a58fd040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将TreeNode类型转化成int\n",
    "for i in range(len(z[0])):\n",
    "    z[0][i]=z[0][i].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d0384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将价格和销量两列拿出来准备聚类和画图\n",
    "file=data[['ITEM_PRICE', 'ITEM_SALES_VOLUME']]\n",
    "#将dataframe变成list格式\n",
    "result=file.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba799d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)\n",
    "train=[]\n",
    "for i in range(len(z[0])):\n",
    "    a=[]\n",
    "    a.append(result[z[0][i]][0])\n",
    "    a.append(result[z[0][i]][1])\n",
    "    train.append(a)\n",
    "#train是待聚类的样本\n",
    "train=np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b68eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a75b1295",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '销量')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 20215 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 26684 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 38144 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 37327 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 20215 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 26684 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 38144 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 37327 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#归一化数据\n",
    "train=preprocessing.scale(train)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(train[:,0],train[:,1])\n",
    "plt.title('label uknown')\n",
    "plt.xlabel('价格')\n",
    "plt.ylabel('销量')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff9323f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'estimator result')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator=KMeans(n_clusters=7)\n",
    "estimator.fit(train)\n",
    "label_pred=estimator.labels_\n",
    "\n",
    "#数据可视化\n",
    "x0=train[label_pred==0]\n",
    "x1=train[label_pred==1]\n",
    "x2=train[label_pred==2]\n",
    "x3=train[label_pred==3]\n",
    "x4=train[label_pred==4]\n",
    "x5=train[label_pred==5]\n",
    "x6=train[label_pred==6]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x0[:,0],x0[:,1],label='0')\n",
    "plt.scatter(x1[:,0],x1[:,1],label='1')\n",
    "plt.scatter(x2[:,0],x2[:,1],label='2')\n",
    "plt.scatter(x3[:,0],x3[:,1],label='3')\n",
    "plt.scatter(x4[:,0],x4[:,1],label='4')\n",
    "plt.scatter(x5[:,0],x5[:,1],label='5')\n",
    "plt.scatter(x6[:,0],x6[:,1],label='6')\n",
    "plt.legend()\n",
    "plt.title('estimator result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ab22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict([[5,12]])\n",
    "estimator.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d720383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class.py\n",
    "\n",
    "class Option:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 0\n",
    "        self.iteration = 0\n",
    "        \n",
    "class NN:\n",
    "    def __init__(self, **arg):\n",
    "        init = {'layer':[],\n",
    "                'active_function':'sigmoid', \n",
    "                'output_function':'sigmoid', \n",
    "                'learning_rate':1.5, \n",
    "                'weight_decay':0,\n",
    "                'cost':{}, \n",
    "                'encoder':0,\n",
    "                'sparsity':0.03,\n",
    "                'beta':3,\n",
    "                'batch_normalization':0,\n",
    "                'grad_squared':0,\n",
    "                'r':0,\n",
    "                'optimization_method':'normal',\n",
    "                'objective_function':'MSE'\n",
    "               }\n",
    "        \n",
    "        param = dict() #字典结构实现参数列表\n",
    "        param.update(init)\n",
    "        param.update(arg)\n",
    "        \n",
    "        self.size = param['layer'] #取出字典的值初始化网络参数\n",
    "        self.depth = len(self.size)\n",
    "        self.active_function = param['active_function']\n",
    "        self.output_function = param['output_function']\n",
    "        self.learning_rate = param['learning_rate']\n",
    "        self.weight_decay = param['weight_decay']\n",
    "        self.encoder = param['encoder']\n",
    "        self.sparsity = param['sparsity']\n",
    "        self.beta = param['beta']\n",
    "        self.cost = param['cost']\n",
    "        self.batch_normalization = param['batch_normalization']\n",
    "        self.grad_squared = param['grad_squared']\n",
    "        self.r = param['r']\n",
    "        self.optimization_method = param['optimization_method']\n",
    "        self.objective_function = param['objective_function']\n",
    "        self.a = dict()\n",
    "\n",
    "        if self.objective_function == 'Cross Entropy':\n",
    "            self.output_function = 'softmax'\n",
    "\n",
    "        self.W = dict(); self.b = dict(); self.vW = dict(); self.vb = dict() #python必须要先初始化字典才能用\n",
    "        self.rW = dict(); self.rb = dict(); self.sW = dict(); self.sb = dict() #注意要单独初始化，否则它们以后也一直是一样的\n",
    "        self.E = dict(); self.S = dict(); self.Gamma = dict(); self.Beta = dict()\n",
    "        self.vGamma = dict(); self.rGamma = dict(); self.vBeta = dict(); self.rBeta = dict(); \n",
    "        self.sGamma = dict(); self.sBeta = dict(); self.W_grad = dict(); self.b_grad = dict(); self.theta = dict()\n",
    "        self.Gamma_grad = dict(); self.Beta_grad = dict()\n",
    "        \n",
    "        for k in range(self.depth - 1):\n",
    "            width = self.size[k]\n",
    "            height = self.size[k + 1]\n",
    "            #self.W{ k } = (np.random.rand(height, width) - 0.5) * 2 * np.sqrt(6 / (height + width + 1)) - np.sqrt(6 / (height + width + 1));\n",
    "\n",
    "            self.W[k] = 2 * np.random.rand(height, width) / np.sqrt(width) - 1 / np.sqrt(width)\n",
    "            \n",
    "            #self.W{ k } = 2 * np.random.rand(height, width) - 1;\n",
    "            #Xavier initialization\n",
    "            if self.active_function == 'relu':\n",
    "                self.b[k] = np.random.rand(height, 1) + 0.01\n",
    "            else:\n",
    "                self.b[k] = 2 * np.random.rand(height, 1) / np.sqrt(width) - 1 / np.sqrt(width)\n",
    "\n",
    "            #parameters for moments\n",
    "            method = self.optimization_method\n",
    "\n",
    "            if method == 'Momentum':\n",
    "                self.vW[k] = np.zeros((height, width), dtype=float)\n",
    "                self.vb[k] = np.zeros((height, 1), dtype=float)\n",
    "\n",
    "            if method == 'AdaGrad' or method == 'RMSProp' or method == 'Adam':\n",
    "                self.rW[k] = np.zeros((height, width), dtype=float)\n",
    "                self.rb[k] = np.zeros((height, 1), dtype=float)\n",
    "\n",
    "            if method == 'Adam':\n",
    "                self.sW[k] = np.zeros((height, width), dtype=float)\n",
    "                self.sb[k] = np.zeros((height, 1), dtype=float)\n",
    "\n",
    "            #parameters for batch normalization.\n",
    "            if self.batch_normalization:\n",
    "                self.E[k] = np.zeros((height, 1), dtype=float)\n",
    "                self.S[k] = np.zeros((height, 1), dtype=float)\n",
    "                self.Gamma[k] = 1\n",
    "                self.Beta[k] = 0\n",
    "\n",
    "                if  method == 'Momentum':\n",
    "                    self.vGamma[k] = 1\n",
    "                    self.vBeta[k] = 0\n",
    "\n",
    "                if method == 'AdaGrad' or method == 'RMSProp' or method == 'Adam':\n",
    "                    self.rW[k] = np.zeros((height, width), dtype=float)\n",
    "                    self.rb[k] = np.zeros((height, 1), dtype=float)\n",
    "                    self.rGamma[k] = 0\n",
    "                    self.rBeta[k] = 0\n",
    "\n",
    "                if  method == 'Adam':\n",
    "                    self.sGamma[k] = 1\n",
    "                    self.sBeta[k] = 0\n",
    "\n",
    "                self.vecNum = 0\n",
    "                \n",
    "            self.W_grad[k] = np.zeros((height, width), dtype=float)\n",
    "#function.py\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"返回对应的概率值\"\"\"\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = np.zeros(x.shape,dtype=float)\n",
    "    for i in range(len(x[0])):\n",
    "        softmax_x[:,i] = exp_x[:,i] / (exp_x[0,i] + exp_x[1,i])\n",
    "        \n",
    "    return softmax_x \n",
    "\n",
    "#nn_applygradient.py\n",
    "\n",
    "def nn_applygradient(nn):\n",
    "    method = nn.optimization_method\n",
    "    if method == 'AdaGrad' or method == 'RMSProp' or method == 'Adam':\n",
    "        grad_squared = 0\n",
    "        if nn.batch_normalization == 0:\n",
    "            for k in range(nn.depth-1):\n",
    "                grad_squared = grad_squared + sum(sum(nn.W_grad[k]**2)) + sum(nn.b_grad[k]**2)\n",
    "        else:\n",
    "            for k in range(nn.depth-1):\n",
    "                grad_squared = grad_squared + sum(sum(nn.W_grad[k]**2)) + sum(nn.b_grad[k]**2) + nn.Gamma[k]**2 + nn.Beta[k]**2\n",
    "\n",
    "    for k in range(nn.depth-1):\n",
    "        if nn.batch_normalization == 0:\n",
    "            if method == 'normal':\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*nn.W_grad[k]\n",
    "                nn.b[k] = nn.b[k] - nn.learning_rate*nn.b_grad[k]\n",
    "                \n",
    "            elif method == 'AdaGrad':\n",
    "                nn.rW[k] = nn.rW[k] + nn.W_grad[k]**2\n",
    "                nn.rb[k] = nn.rb[k] + nn.b_grad[k]**2\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*nn.W_grad[k]/(np.sqrt(nn.rW[k]) + 0.001)\n",
    "                nn.b[k] = nn.b[k] - nn.learning_rate*nn.b_grad[k]/(np.sqrt(nn.rb[k]) + 0.001)\n",
    "                \n",
    "            elif method == 'Momentum':\n",
    "                rho = 0.1 #rho = 0.1\n",
    "                nn.vW[k] = rho * nn.vW[k] - nn.learning_rate*nn.W_grad[k]\n",
    "                nn.vb[k] = rho * nn.vb[k] - nn.learning_rate*nn.b_grad[k]\n",
    "                nn.W[k] = nn.W[k] + nn.vW[k]\n",
    "                nn.b[k] = nn.b[k] + nn.vb[k]\n",
    "\n",
    "            elif method == 'RMSProp':\n",
    "                rho = 0.9 #rho = 0.9\n",
    "                nn.rW[k] = rho * nn.rW[k] + 0.1*nn.W_grad[k]**2\n",
    "                nn.rb[k] = rho * nn.rb[k] + 0.1*nn.b_grad[k]**2\n",
    "\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*nn.W_grad[k]/(np.sqrt(nn.rW[k]) + 0.001)\n",
    "                nn.b[k] = nn.b[k] - nn.learning_rate*nn.b_grad[k]/(np.sqrt(nn.rb[k]) + 0.001) #rho = 0.9\n",
    "\n",
    "            elif method == 'Adam':\n",
    "                rho1 = 0.9\n",
    "                rho2 = 0.999\n",
    "                nn.sW[k] = 0.9*nn.sW[k] + 0.1*nn.W_grad[k]\n",
    "                nn.sb[k] = 0.9*nn.sb[k] + 0.1*nn.b_grad[k]\n",
    "                nn.rW[k] = 0.999*nn.rW[k] + 0.001*nn.W_grad[k]**2\n",
    "                nn.rb[k] = 0.999*nn.rb[k] + 0.001*nn.b_grad[k]**2\n",
    "\n",
    "                newS = nn.sW[k] / (1 - rho1)\n",
    "                newR = nn.rW[k] / (1 - rho2)\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*newS/np.sqrt(newR + 0.00001)\n",
    "                newS = nn.sb[k] / (1 - rho1)\n",
    "                newR = nn.rb[k] / (1 - rho2)\n",
    "                nn.b[k] = nn.b[k] -nn.learning_rate*newS/np.sqrt(newR + 0.00001)#rho1 = 0.9, rho2 = 0.999, delta = 0.00001\n",
    "\n",
    "        else:\n",
    "            if method == 'normal':\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*nn.W_grad[k]\n",
    "                nn.b[k] = nn.b[k] - nn.learning_rate*nn.b_grad[k]\n",
    "                nn.Gamma[k] = nn.Gamma[k] - nn.learning_rate*nn.Gamma_grad[k]\n",
    "                nn.Beta[k] = nn.Beta[k] - nn.learning_rate*nn.Beta_grad[k]\n",
    "                \n",
    "            elif method == 'AdaGrad':\n",
    "                nn.rW[k] = nn.rW[k] + nn.W_grad[k]**2\n",
    "                nn.rb[k] = nn.rb[k] + nn.b_grad[k]**2\n",
    "                nn.rGamma[k] = nn.rGamma[k] + nn.Gamma_grad[k]**2\n",
    "                nn.rBeta[k] = nn.rBeta[k] + nn.Beta_grad[k]**2\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*nn.W_grad[k]/(np.sqrt(nn.rW[k]) + 0.001)\n",
    "                nn.b[k] = nn.b[k] - nn.learning_rate*nn.b_grad[k]/(np.sqrt(nn.rb[k]) + 0.001)\n",
    "                nn.Gamma[k] = nn.Gamma[k] - nn.learning_rate*nn.Gamma_grad[k] / (np.sqrt(nn.rGamma[k]) + 0.001)\n",
    "                nn.Beta[k] = nn.Beta[k] - nn.learning_rate*nn.Beta_grad[k] / (np.sqrt(nn.rBeta[k]) + 0.001)\n",
    "                \n",
    "            elif method == 'RMSProp':\n",
    "                nn.rW[k] = 0.9*nn.rW[k] + 0.1*nn.W_grad[k]**2\n",
    "                nn.rb[k] = 0.9*nn.rb[k] + 0.1*nn.b_grad[k]**2\n",
    "                nn.rGamma[k] = 0.9*nn.rGamma[k] + 0.1*nn.Gamma_grad[k]**2\n",
    "                nn.rBeta[k] = 0.9*nn.rBeta[k] + 0.1*nn.Beta_grad[k]**2\n",
    "                nn.W[k] = nn.W[k] - nn.learning_rate*nn.W_grad[k]/(np.sqrt(nn.rW[k]) + 0.001)\n",
    "                nn.b[k] = nn.b[k] - nn.learning_rate*nn.b_grad[k]/(np.sqrt(nn.rb[k]) + 0.001)\n",
    "                nn.Gamma[k] = nn.Gamma[k] - nn.learning_rate*nn.Gamma_grad[k] / (np.sqrt(nn.rGamma[k]) + 0.001)\n",
    "                nn.Beta[k] = nn.Beta[k] - nn.learning_rate*nn.Beta_grad[k] / (np.sqrt(nn.rBeta[k]) + 0.001) #rho = 0.9\n",
    "\n",
    "            elif method == 'Momentum':\n",
    "                rho = 0.1 #rho = 0.1\n",
    "                nn.vW[k] = rho * nn.vW[k] - nn.learning_rate*nn.W_grad[k]\n",
    "                nn.vb[k] = rho * nn.vb[k] - nn.learning_rate*nn.b_grad[k]\n",
    "                nn.vGamma[k] = rho * nn.vGamma[k] - nn.learning_rate*nn.Gamma_grad[k]\n",
    "                nn.vBeta[k] = rho * nn.vBeta[k] - nn.learning_rate*nn.Beta_grad[k]\n",
    "                nn.W[k] = nn.W[k] + nn.vW[k]\n",
    "                nn.b[k] = nn.b[k] + nn.vb[k]\n",
    "                nn.Gamma[k] = nn.Gamma[k] + nn.vGamma[k]\n",
    "                nn.Beta[k] = nn.Beta[k] + nn.vBeta[k]\n",
    "\n",
    "            elif method == 'Adam':\n",
    "                nn.sW[k] = 0.9*nn.sW[k] + 0.1*nn.W_grad[k]\n",
    "                nn.sb[k] = 0.9*nn.sb[k] + 0.1*nn.b_grad[k]\n",
    "                nn.sGamma[k] = 0.9*nn.sGamma[k] + 0.1*nn.Gamma_grad[k]\n",
    "                nn.sBeta[k] = 0.9*nn.sBeta[k] + 0.1*nn.Beta_grad[k]\n",
    "                nn.rW[k] = 0.999*nn.rW[k] + 0.001*nn.W_grad[k]**2\n",
    "                nn.rb[k] = 0.999*nn.rb[k] + 0.001*nn.b_grad[k]**2\n",
    "                nn.rBeta[k] = 0.999*nn.rBeta[k] + 0.001*nn.Beta_grad[k]**2\n",
    "                nn.rGamma[k] = 0.999*nn.rGamma[k] + 0.001*nn.Gamma_grad[k]**2\n",
    "                nn.W[k] = nn.W[k] -10 * nn.learning_rate*nn.sW[k]/np.sqrt(1000 * nn.rW[k]+0.00001)\n",
    "                nn.b[k] = nn.b[k] -10 * nn.learning_rate*nn.sb[k]/np.sqrt(1000 * nn.rb[k]+0.00001)\n",
    "                nn.Gamma[k] = nn.Gamma[k] -10 * nn.learning_rate*nn.sGamma[k]/np.sqrt(1000 * nn.rGamma[k]+0.00001)\n",
    "                nn.Beta[k] = nn.Beta[k] -10 * nn.learning_rate*nn.sBeta[k]/np.sqrt(1000 * nn.rBeta[k]+0.00001) #rho1 = 0.9, rho2 = 0.999, delta = 0.00001\n",
    "\n",
    "    return nn\n",
    "\n",
    "#nn_forward.py\n",
    "def nn_forward(nn, batch_x, batch_y):\n",
    "    s = len(nn.cost) + 1 \n",
    "    batch_x = batch_x.T \n",
    "    batch_y = batch_y.T \n",
    "    m = batch_x.shape[1]\n",
    "    nn.a[0] = batch_x \n",
    "\n",
    "    cost2 = 0 \n",
    "    for k in range(1, nn.depth):\n",
    "        y = np.dot(nn.W[k-1], nn.a[k-1]) + np.tile(nn.b[k-1], (1, m)) #np.tile就是matlab中的repmat(replicate matrix)\n",
    "        \n",
    "        if nn.batch_normalization:\n",
    "            nn.E[k-1] = nn.E[k-1]*nn.vecNum + np.array([np.sum(y, axis=1)]).T\n",
    "            nn.S[k-1] = nn.S[k-1]**2 * (nn.vecNum - 1) + np.array([(m - 1)*np.std(y,ddof=1,axis=1)** 2]).T #ddof=1计算无偏估计\n",
    "            nn.vecNum = nn.vecNum + m \n",
    "            nn.E[k-1] = nn.E[k-1] / nn.vecNum \n",
    "            nn.S[k-1] = np.sqrt(nn.S[k-1] / (nn.vecNum - 1)) \n",
    "            y = (y - np.tile(nn.E[k-1], (1, m))) / np.tile(nn.S[k-1]+0.0001*np.ones(nn.S[k-1].shape), (1, m)) \n",
    "            y = nn.Gamma[k-1]*y + nn.Beta[k-1] \n",
    "\n",
    "        if k == nn.depth - 1:\n",
    "            f = nn.output_function\n",
    "            if f == 'sigmoid' :\n",
    "                nn.a[k] = sigmoid(y)\n",
    "            elif f == 'tanh' :\n",
    "                nn.a[k] = np.tanh(y)\n",
    "            elif f == 'relu' :\n",
    "                nn.a[k] = np.maximum(y, 0)\n",
    "            elif f == 'softmax' :\n",
    "                nn.a[k] = softmax(y)\n",
    "\n",
    "        else:\n",
    "            f = nn.active_function\n",
    "            if f == 'sigmoid' :\n",
    "                nn.a[k] = sigmoid(y)\n",
    "            elif f == 'tanh' :\n",
    "                nn.a[k] = np.tanh(y)\n",
    "            elif f == 'relu' :\n",
    "                nn.a[k] = np.maximum(y, 0)\n",
    "\n",
    "        cost2 = cost2 + np.sum(nn.W[k-1]**2)\n",
    "\n",
    "    if nn.encoder == 1:\n",
    "        roj = np.sum(nn.a[2], axis=1) / m \n",
    "        nn.cost[s] = 0.5 * np.sum((nn.a[k] -batch_y)**2) / m + 0.5 * nn.weight_decay * cost2 + 3 * sum(nn.sparsity * np.log(nn.sparsity / roj) + (1-nn.sparsity) * np.log((1-nn.sparsity) / (1-roj)))\n",
    "    else:\n",
    "        if nn.objective_function == 'MSE':\n",
    "            nn.cost[s] = 0.5 / m * sum(sum((nn.a[k] -batch_y)** 2)) + 0.5 * nn.weight_decay * cost2 \n",
    "        elif nn.objective_function == 'Cross Entropy':\n",
    "            nn.cost[s] = -0.5 * sum(sum(batch_y*np.log(nn.a[k]))) / m + 0.5 * nn.weight_decay * cost2 \n",
    "    # nn.cost[s]\n",
    "    \n",
    "    return nn\n",
    "\n",
    "#nn_backpropagation.py\n",
    "\n",
    "def nn_backpropagation(nn, batch_y) :\n",
    "    batch_y = batch_y.T\n",
    "    m = nn.a[0].shape[1]\n",
    "    nn.theta[1] = 0\n",
    "    f = nn.output_function\n",
    "    if f == 'sigmoid' :\n",
    "        nn.theta[nn.depth-1] = -(batch_y - nn.a[nn.depth-1]) * nn.a[nn.depth-1] * (1 - nn.a[nn.depth-1])\n",
    "    if f == 'tanh' :\n",
    "        nn.theta[nn.depth-1] = -(batch_y - nn.a[nn.depth-1]) * (1 - nn.a[nn.depth-1]**2)\n",
    "    if f == 'softmax' :\n",
    "        y = np.dot(nn.W[nn.depth - 2], nn.a[nn.depth - 2]) + np.tile(nn.b[nn.depth - 2], (1, m))\n",
    "        nn.theta[nn.depth-1] = nn.a[nn.depth-1] - batch_y\n",
    "\n",
    "    if nn.batch_normalization :\n",
    "        x = np.dot(nn.W[nn.depth - 2], nn.a[nn.depth -2]) + np.tile(nn.b[nn.depth - 2], (1, m))\n",
    "        x = (x - np.tile(nn.E[nn.depth -2], (1, m))) / np.tile(nn.S[nn.depth -2] + 0.0001*np.ones(nn.S[nn.depth - 2].shape), (1, m))\n",
    "        temp = nn.theta[nn.depth-1] * x\n",
    "        nn.Gamma_grad[nn.depth - 2] = sum(np.mean(temp, axis = 1))\n",
    "        nn.Beta_grad[nn.depth - 2] = sum(np.mean(nn.theta[nn.depth-1], axis = 1))\n",
    "        nn.theta[nn.depth - 1] = nn.Gamma[nn.depth - 2]*nn.theta[nn.depth-1] / np.tile((nn.S[nn.depth - 2] + 0.0001), (1, m))\n",
    "\n",
    "    nn.W_grad[nn.depth - 2] = np.dot(nn.theta[nn.depth-1], nn.a[nn.depth - 2].T) / m + nn.weight_decay*nn.W[nn.depth - 2]\n",
    "    nn.b_grad[nn.depth - 2] = np.array([np.sum(nn.theta[nn.depth-1], axis=1) / m]).T \n",
    "    #因为np.sum()返回维度为(n,)，会让之后的加法操作错误，所以要转换为(n,1)维度矩阵，下面的也是一样\n",
    "    \n",
    "    f = nn.active_function\n",
    "    if f == 'sigmoid':\n",
    "        if nn.encoder == 0 :\n",
    "            for ll in range(1, nn.depth - 1) :\n",
    "                k = nn.depth - ll-1\n",
    "                nn.theta[k] = np.dot(nn.W[k].T, nn.theta[k + 1])*nn.a[k]* (1 - nn.a[k])\n",
    "                if nn.batch_normalization :\n",
    "                    x = np.dot(nn.W[k - 1], nn.a[k - 1]) + np.tile(nn.b[k - 1], (1, m))\n",
    "                    x = (x - np.tile(nn.E[k - 1], (1, m))) / np.tile(nn.S[k - 1] + 0.0001*np.ones(nn.S[k - 1].shape), (1, m))\n",
    "                    temp = nn.theta[k]*x\n",
    "                    nn.Gamma_grad[k - 1] = sum(np.mean(temp, axis = 1))\n",
    "                    nn.Beta_grad[k - 1] = sum(np.mean(nn.theta[k], axis = 1))\n",
    "                    nn.theta[k] = (nn.Gamma[k - 1]* nn.theta[k]) / np.tile((nn.S[k - 1] + 0.0001), (1, m))\n",
    "                    pass\n",
    "\n",
    "                nn.W_grad[k - 1] = np.dot(nn.theta[k], nn.a[k - 1].T) / m + nn.weight_decay*nn.W[k - 1]\n",
    "                nn.b_grad[k - 1] = np.array([np.sum(nn.theta[k], axis = 1) / m]).T\n",
    "\n",
    "        else:\n",
    "            #encoder完全按照matlab的NN，但貌似是有错误的，用encoder会报错，因为theta[2]（对应matlab的theta{3}）没有赋值\n",
    "            roj = np.array([np.sum(nn.a[1], axis = 1) / m]).T \n",
    "            temp = (-nn.sparsity / roj + (1 - nn.sparsity) / (1 - roj))\n",
    "            nn.theta[1] = (np.dot(nn.W[1].T, nn.theta[2]) + nn.beta*repmat(temp, 1, m))*M\n",
    "            nn.W_grad[0] = np.dot(nn.theta[1], nn.a[0].T) / m + nn.weight_decay*nn.W[0]\n",
    "            nn.b_grad[0] = np.array([np.sum(nn.theta[1], axis = 1) / m]).T\n",
    "            \n",
    "\n",
    "    elif f == 'tanh':\n",
    "        for ll in range(1, nn.depth-1) :\n",
    "            if nn.encoder == 0 :\n",
    "                k = nn.depth - ll-1 \n",
    "                nn.theta[k] = np.dot(nn.W[k].T,nn.theta[k + 1])*(1 - nn.a[k]**2)\n",
    "                if nn.batch_normalization :\n",
    "                    x = np.dot(nn.W[k - 1], nn.a[k - 1]) + np.tile(nn.b[k - 1], (1, m))\n",
    "                    x = (x - np.tile(nn.E[k - 1], (1, m))) / np.tile(nn.S[k - 1] + 0.0001*np.ones(nn.S[k - 1].shape), (1, m))\n",
    "                    temp = nn.theta[k]*x\n",
    "                    nn.Gamma_grad[k - 1] = sum(np.mean(temp, axis = 1))\n",
    "                    nn.Beta_grad[k - 1] = sum(np.mean(nn.theta[k], axis = 1))\n",
    "                    nn.theta[k] = (nn.Gamma[k - 1]* nn.theta[k]) / np.tile((nn.S[k - 1] + 0.0001), (1, m))\n",
    "                    pass\n",
    "\n",
    "                nn.W_grad[k - 1] = np.dot(nn.theta[k], nn.a[k - 1].T) / m + nn.weight_decay*nn.W[k - 1]\n",
    "                nn.b_grad[k - 1] = np.array([np.sum(nn.theta[k], axis = 1) / m]).T\n",
    "\n",
    "            else:\n",
    "                roj = np.array([np.sum(nn.a[1], axis = 1) / m]).T\n",
    "                temp = (-nn.sparsity / roj + (1 - nn.sparsity) / (1 - roj))\n",
    "                nn.theta[1] = (np.dot(nn.W[1].T, nn.theta[2]) + nn.beta*repmat(temp, 1, m))*M\n",
    "                nn.W_grad[0] = np.dot(nn.theta[1], nn.a[0].T) / m + nn.weight_decay*nn.W[0]\n",
    "                nn.b_grad[0] = np.array([np.sum(nn.theta[1], axis = 1) / m]).T\n",
    "\n",
    "    elif f == 'relu':\n",
    "        if nn.encoder == 0 :\n",
    "            for ll in range(1, nn.depth - 1) :\n",
    "                k = nn.depth - ll-1\n",
    "                nn.theta[k] = np.dot(nn.W[k].T,nn.theta[k + 1])* (nn.a[k] > 0)\n",
    "                if nn.batch_normalization :\n",
    "                    x = np.dot(nn.W[k - 1], nn.a[k - 1]) + np.tile(nn.b[k - 1], (1, m))\n",
    "                    x = (x - np.tile(nn.E[k - 1], (1, m))) / np.tile(nn.S[k - 1] + 0.0001*np.ones(nn.S[k - 1].shape), (1, m))\n",
    "                    temp = nn.theta[k]*x\n",
    "                    nn.Gamma_grad[k - 1] = sum(np.mean(temp, axis = 1))\n",
    "                    nn.Beta_grad[k - 1] = sum(np.mean(nn.theta[k], axis = 1))\n",
    "                    nn.theta[k] = (nn.Gamma[k - 1]* nn.theta[k]) / np.tile((nn.S[k - 1] + 0.0001), (1, m))\n",
    "                    pass\n",
    "\n",
    "                nn.W_grad[k - 1] = np.dot(nn.theta[k], nn.a[k - 1].T) / m + nn.weight_decay*nn.W[k - 1]\n",
    "                nn.b_grad[k - 1] = np.array([np.sum(nn.theta[k], axis = 1) / m]).T\n",
    "\n",
    "        else:\n",
    "            roj = np.array([np.sum(nn.a[1], axis = 1) / m]).T\n",
    "            temp = (-nn.sparsity / roj + (1 - nn.sparsity) / (1 - roj))\n",
    "            M = np.maximum(nn.a[1], 0)\n",
    "            M = M / np.maximum(M, 0.001)\n",
    "\n",
    "            nn.theta[1] = (np.dot(nn.W[1].T, nn.theta[2]) + nn.beta*repmat(temp, 1, m))*M\n",
    "            nn.W_grad[0] = np.dot(nn.theta[1], nn.a[0].T) / m + nn.weight_decay*nn.W[0]\n",
    "            nn.b_grad[0] = np.array([np.sum(nn.theta[1], axis = 1) / m]).T\n",
    "    return nn\n",
    "\n",
    "#nn_predict.py\n",
    "\n",
    "def nn_predict(nn, batch_x):\n",
    "    batch_x = batch_x.T \n",
    "    m = batch_x.shape[1]\n",
    "    nn.a[0] = batch_x \n",
    "    for k in range(1, nn.depth):\n",
    "        y = np.dot(nn.W[k-1], nn.a[k-1]) + np.tile(nn.b[k-1], (1, m))\n",
    "        if nn.batch_normalization:\n",
    "            y = (y - np.tile(nn.E[k-1], (1, m))) / np.tile(nn.S[k-1]+0.0001*np.ones(nn.S[k-1].shape), (1, m)) \n",
    "            y = nn.Gamma[k-1]*y + nn.Beta[k-1] \n",
    "\n",
    "        if k == nn.depth-1:\n",
    "            f = nn.output_function\n",
    "            if f == 'sigmoid':\n",
    "                nn.a[k] = sigmoid(y) \n",
    "            elif f == 'tanh':\n",
    "                nn.a[k] = np.tanh(y) \n",
    "            elif f == 'relu':\n",
    "                nn.a[k] = np.maximum(y, 0) \n",
    "            elif f == 'softmax':\n",
    "                nn.a[k] = softmax(y) \n",
    "\n",
    "        else:\n",
    "            f = nn.active_function\n",
    "            if f == 'sigmoid':\n",
    "                nn.a[k] = sigmoid(y) \n",
    "            elif f == 'tanh':\n",
    "                nn.a[k] = np.tanh(y) \n",
    "            elif f == 'relu':\n",
    "                nn.a[k] = np.maximum(y, 0) \n",
    "            \n",
    "    return nn\n",
    "\n",
    "#nn_train.py\n",
    "\n",
    "def nn_train(nn,option,train_x,train_y):\n",
    "    iteration = option.iteration\n",
    "    batch_size = option.batch_size\n",
    "    m = train_x.shape[0]\n",
    "    num_batches = m / batch_size\n",
    "    for k in range(iteration): \n",
    "        kk = np.random.permutation(m)\n",
    "        for l in range(int(num_batches)):\n",
    "            batch_x = train_x[kk[l * batch_size : (l + 1) * batch_size], :] #(l+1)*batch_size也可以改成max((l+1)*batch_size, len(kk))\n",
    "            batch_y = train_y[kk[l * batch_size : (l + 1) * batch_size], :]\n",
    "            nn = nn_forward(nn,batch_x,batch_y)\n",
    "            nn = nn_backpropagation(nn,batch_y)\n",
    "            nn = nn_applygradient(nn)\n",
    "            \n",
    "    return nn\n",
    "\n",
    "#nn_test.py\n",
    "\n",
    "def nn_test(nn,test_x,test_y):\n",
    "    nn = nn_predict(nn,test_x)\n",
    "    y_output = nn.a[nn.depth-1]\n",
    "    y_output = y_output.T\n",
    "    label = np.argmax(y_output, axis=1) #按行找出最大元素所在下标\n",
    "    expectation = np.argmax(test_y, axis=1)\n",
    "    wrongs = sum(label != expectation) #求预测与期望不相等的个数\n",
    "    success_ratio = 1-wrongs/test_y.shape[0]\n",
    "    \n",
    "    return wrongs, success_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b52c2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "def nn_testChess():\n",
    "    with open('krkopt.data') as my_data:  # 读取文件部分\n",
    "        lines = my_data.readlines()\n",
    "        data = np.zeros((28056, 6), dtype=float)\n",
    "        label = np.zeros((28056, 2), dtype=float)\n",
    "        i = 0\n",
    "        for line in lines:\n",
    "            line = line.split(',')  # 以逗号分开\n",
    "            if i == 0:\n",
    "                line[0] = 'a'  # 不知道为什么第一个数据乱码，用写字板打开是'a'\n",
    "\n",
    "            line[0] = ord(line[0]) - 96\n",
    "            line[1] = float(line[1]) - 48\n",
    "            line[2] = ord(line[2]) - 96\n",
    "            line[3] = float(line[3]) - 48\n",
    "            line[4] = ord(line[4]) - 96\n",
    "            line[5] = float(line[5]) - 48\n",
    "            data[i, :] = line[:-1]\n",
    "\n",
    "            if line[6][0] == 'd':\n",
    "                label[i] = np.array([1, 0])\n",
    "            else:\n",
    "                label[i] = np.array([0, 1])\n",
    "            i += 1\n",
    "            if i == 28056:\n",
    "                break\n",
    "\n",
    "    ratioTraining = 0.4\n",
    "    ratioValidation = 0.1\n",
    "    ratioTesting = 0.5\n",
    "    xTraining, xTesting, yTraining, yTesting = train_test_split(data, label, test_size=1 - ratioTraining,\n",
    "                                                                random_state=0)  # 随机分配数据集\n",
    "    xTesting, xValidation, yTesting, yValidation = train_test_split(xTesting, yTesting,\n",
    "                                                                    test_size=ratioValidation / ratioTesting,\n",
    "                                                                    random_state=0)\n",
    "    # 拆分成测试集和验证集\n",
    "\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit(xTraining)\n",
    "    scaler.transform(xTraining)  # 标准归一化\n",
    "    scaler.transform(xTesting)\n",
    "    scaler.transform(xValidation)\n",
    "\n",
    "    nn = NN(layer=[6, 20, 20, 20, 2], active_function='relu', learning_rate=0.01, batch_normalization=1,\n",
    "            optimization_method='Adam',\n",
    "            objective_function='Cross Entropy')\n",
    "\n",
    "    option = Option()\n",
    "    option.batch_size = 50\n",
    "    option.iteration = 1\n",
    "\n",
    "    iteration = 0\n",
    "    maxAccuracy = 0\n",
    "    totalAccuracy = []\n",
    "    totalCost = []\n",
    "    maxIteration = 20\n",
    "    while iteration < maxIteration:\n",
    "        iteration = iteration + 1\n",
    "        nn = nn_train(nn, option, xTraining, yTraining)\n",
    "        totalCost.append(sum(nn.cost.values()) / len(nn.cost.values()))\n",
    "        # plot(totalCost)\n",
    "        (wrongs, accuracy) = nn_test(nn, xValidation, yValidation)\n",
    "        totalAccuracy.append(accuracy)\n",
    "        if accuracy > maxAccuracy:\n",
    "            maxAccuracy = accuracy\n",
    "            storedNN = nn\n",
    "\n",
    "        cost = totalCost[iteration - 1]\n",
    "        print(accuracy)\n",
    "        print(totalCost[iteration - 1])\n",
    "\n",
    "    subplot(2, 1, 1)\n",
    "    plot(totalCost, color='red')\n",
    "    title('Average Objective Function Value on the Training Set')\n",
    "\n",
    "    subplot(2, 1, 2)\n",
    "    plot(totalAccuracy, color='red')\n",
    "    ylim([0.8, 1])\n",
    "    title('Accuracy on the Validation Set')\n",
    "    tight_layout(2)\n",
    "    show()\n",
    "\n",
    "    wrongs, accuracy = nn_test(storedNN, xTesting, yTesting)\n",
    "    print('acc:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d2e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "        strlen=select_data.shape[0]\n",
    "        data = np.zeros((strlen, 2), dtype=float)\n",
    "        label = np.zeros((strlen, 2), dtype=int)\n",
    "        for i in range(m):\n",
    "            data[i][0]=select_data.iloc[i,4]\n",
    "            data[i][1]=select_data.iloc[i,5]\n",
    "            if(select_data.iloc[i,14]==0):\n",
    "                label[i]=np.array([0,1])\n",
    "            else:\n",
    "                label[i]=np.array([1,0])\n",
    "            \n",
    "        ratioTraining = 0.4\n",
    "        ratioValidation = 0.1\n",
    "        ratioTesting = 0.5\n",
    "        xTraining, xTesting, yTraining, yTesting = train_test_split(data, label, test_size=1 - ratioTraining,\n",
    "                                                                random_state=0)  # 随机分配数据集\n",
    "        xTesting, xValidation, yTesting, yValidation = train_test_split(xTesting, yTesting,\n",
    "                                                                    test_size=ratioValidation / ratioTesting,\n",
    "                                                                    random_state=0)\n",
    "        # 拆分成测试集和验证集\n",
    "\n",
    "        scaler = StandardScaler(copy=False)\n",
    "        scaler.fit(xTraining)\n",
    "        scaler.transform(xTraining)  # 标准归一化\n",
    "        scaler.transform(xTesting)\n",
    "        scaler.transform(xValidation)\n",
    "        \n",
    "        nn = NN(layer=[2, 20, 20, 20, 2], active_function='relu', learning_rate=0.01, batch_normalization=1,\n",
    "            optimization_method='Adam',\n",
    "            objective_function='Cross Entropy')\n",
    "\n",
    "        option = Option()\n",
    "        option.batch_size = 50\n",
    "        option.iteration = 1  \n",
    "        \n",
    "        iteration = 0\n",
    "        maxAccuracy = 0\n",
    "        totalAccuracy = []\n",
    "        totalCost = []\n",
    "        maxIteration = 20\n",
    "        while iteration < maxIteration:\n",
    "            iteration = iteration + 1\n",
    "            nn = nn_train(nn, option, xTraining, yTraining)\n",
    "            totalCost.append(sum(nn.cost.values()) / len(nn.cost.values()))\n",
    "            # plot(totalCost)\n",
    "            (wrongs, accuracy) = nn_test(nn, xValidation, yValidation)\n",
    "            totalAccuracy.append(accuracy)\n",
    "            if accuracy > maxAccuracy:\n",
    "                maxAccuracy = accuracy\n",
    "                storedNN = nn\n",
    "\n",
    "            cost = totalCost[iteration - 1]\n",
    "            print(accuracy)\n",
    "            print(totalCost[iteration - 1])\n",
    "            \n",
    "        subplot(2, 1, 1)\n",
    "        plot(totalCost, color='red')\n",
    "        title('Average Objective Function Value on the Training Set')\n",
    "\n",
    "        subplot(2, 1, 2)\n",
    "        plot(totalAccuracy, color='red')\n",
    "        ylim([0.8, 1])\n",
    "        title('Accuracy on the Validation Set')\n",
    "        tight_layout(2)\n",
    "        show()\n",
    "\n",
    "        wrongs, accuracy = nn_test(storedNN, xTesting, yTesting)\n",
    "        print('acc:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9d5f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9913793103448276\n",
      "0.13601712064976526\n",
      "0.9956896551724138\n",
      "0.08367963196105475\n",
      "0.9956896551724138\n",
      "0.058058371995336505\n",
      "0.9913793103448276\n",
      "0.04456074073721991\n",
      "0.9913793103448276\n",
      "0.03658014767744508\n",
      "0.9956896551724138\n",
      "0.03174201659834208\n",
      "0.9956896551724138\n",
      "0.0281679151806972\n",
      "0.9913793103448276\n",
      "0.024951467245972567\n",
      "0.9956896551724138\n",
      "0.022455414981540103\n",
      "0.9913793103448276\n",
      "0.020535144059253146\n",
      "0.9956896551724138\n",
      "0.01886524582633593\n",
      "0.9913793103448276\n",
      "0.017441693915949488\n",
      "0.9956896551724138\n",
      "0.016268395844097536\n",
      "0.9956896551724138\n",
      "0.0152389446641116\n",
      "0.9956896551724138\n",
      "0.01431256170588627\n",
      "0.9956896551724138\n",
      "0.013494928908428138\n",
      "0.9956896551724138\n",
      "0.012781302140974442\n",
      "0.9956896551724138\n",
      "0.012137074264000168\n",
      "0.9956896551724138\n",
      "0.011566126139657138\n",
      "0.9956896551724138\n",
      "0.011068881628740077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-0782625da566>:65: MatplotlibDeprecationWarning: Passing the pad parameter of tight_layout() positionally is deprecated since Matplotlib 3.3; the parameter will become keyword-only two minor releases later.\n",
      "  tight_layout(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9989189189189189\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60450012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
